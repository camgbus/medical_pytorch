# ------------------------------------------------------------------------------
# This class builds a descendant of torch.utils.data.Dataset from a 
# mp.data.datasets.dataset.Dataset and a list of instance indexes.
# ------------------------------------------------------------------------------

import os
import torch
import random
from mp.paths import storage_data_path
from torch.utils.data import Dataset

class PytorchDataset(Dataset):
    def __init__(self, dataset, ix_lst=None, size=None, save_restore_k=None):
        r"""A dataset which is compatible with PyTorch.

        Args:
            dataset (mp.data.datasets.dataset.Dataset): a descendant of the
                class defined internally for datasets.
            ix_lst (list[int]): list specifying the instances of 'dataset' to
                include. If 'None', all which are not in the hold-out dataset
                are incuded.
            size (tuple[int]): desired input size.

        :param resize: resize images into this new size.
        :param transform_lst: a list of torchvision transforms operations.
        :param norm: values to normalize the dataset with the form
        {'mean': tuple, 'std': tuple}, which can be generated by
        mp.utils.pytorch.compute_normalization_values
        """
        # Indexes
        if ix_lst is None:
            ix_lst = [ix for ix in range(len(dataset.instances))
                if ix not in dataset.hold_out_ixs]
        self.instances = [ex for ix, ex in enumerate(dataset.instances)
            if ix in ix_lst]
        self.size = size
        self.ds_name = dataset.name
        # To save and restore items
        self.restore_items = False
        if save_restore_k is not None:
            self.restore_items = True
            self.k = save_restore_k
            self.save_path = os.path.join(storage_data_path, 'static_data',
            super().__class__.__name__, self.ds_name)
            if not os.path.isdir(self.save_path):
                self._save_items()

    def __len__(self):
        return len(self.instances)

    def _save_items(self, original_dataset):
        for kix in self.k:
            for idx in range(self.__len__()):
                inputs, outputs = self.__getitem__(idx)
                inputs_name = 'X_'+str(idx)+'_'+str(kix)+'.pt'
                outputs_name = 'Y_'+str(idx)+'_'+str(kix)+'.pt'
                torch.save(inputs, inputs_name)
                torch.save(outputs, outputs_name)

    def _get_saved_item(self, idx):
        # Select ix in [0, k-1]
        kix = random.randint(0, self.k)
        # Load data
        inputs_name = 'X_'+str(idx)+'_'+str(kix)+'.pt'
        outputs_name = 'Y_'+str(idx)+'_'+str(kix)+'.pt'
        inputs = torch.load(inputs_name)
        outputs = torch.load(outputs_name)
        return inputs, outputs
